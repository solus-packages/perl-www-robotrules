name       : perl-www-robotrules
version    : 6.02
release    : 7
source     :
    - https://cpan.metacpan.org/authors/id/G/GA/GAAS/WWW-RobotRules-6.02.tar.gz : 46b502e7a288d559429891eeb5d979461dd3ecc6a5c491ead85d165b6e03a51e
license    : Artistic-1.0-Perl
component  : programming.perl
summary    : WWW::RobotRules - database of robots.txt-derived permissions
description: |
    This module parses /robots.txt files as specified in "A Standard for Robot Exclusion", at <http://www.robotstxt.org/wc/norobots.html> Webmasters can use the /robots.txt file to forbid conforming robots from accessing parts of their web site. The parsed files are kept in a WWW::RobotRules object, and this object provides methods to check if access to a given URL is prohibited. The same WWW::RobotRules object can be used for one or more parsed /robots.txt files on any number of hosts.
rundeps    :
    - perl-uri
setup      : |
    %perl_setup
build      : |
    %perl_build
install    : |
    %perl_install
